{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre trained network\n",
    "![imagen](https://www.researchgate.net/publication/336874848/figure/fig1/AS:819325225144320@1572353764073/Illustrations-of-transfer-learning-a-neural-network-is-pretrained-on-ImageNet-and.png)\n",
    "\n",
    "Estas son las arquitecturas de redes neuronales más utilizadas en la comunidad. Para más detalle sobre el funcionamiento de cada red, consultar el [Hands on Machine Learning for Python](https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch14.html#cnn_chapter).\n",
    "* VGG-16\n",
    "* VGG-19\n",
    "* Inception V3\n",
    "* XCeption\n",
    "* ResNet-50\n",
    "\n",
    "Las redes se pueden incorporar entrenadas, o sin entrenar.\n",
    "\n",
    "## ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# from skimage.io import imread\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, decode_predictions, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50V2??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m102869336/102869336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# CODE MODEL\n",
    "base_model = ResNet50V2(include_top= True, input_shape=(224, 224, 3), weights='imagenet', classifier_activation= 'softmax')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = base_model.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE READ DATA\n",
    "\n",
    "import os\n",
    "\n",
    "def read_data(path):\n",
    "    X = []\n",
    "    for file in os.listdir(path):\n",
    "        image = plt.imread(path + '/' + file)\n",
    "        smallimage = cv2.resize(image, (224,224))\n",
    "        print(path + '/' + file)\n",
    "\n",
    "        X.append(smallimage)\n",
    "    return np.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img/batman.jpg\n",
      "img/bear-1.jpg\n",
      "img/cat.8016.jpg\n",
      "img/cat.8037.jpg\n",
      "img/dog.11856.jpg\n",
      "img/dog.11857.jpg\n",
      "img/horse.jpg\n",
      "img/karate.jpg\n",
      "img/pizza.jpg\n",
      "(9, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test = read_data('img')\n",
    "\n",
    "#Preprocesar las imagenes tal y como entran en el model\n",
    "X_test = preprocess_input(X_test)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "# CODE preds\n",
    "\n",
    "preds = base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "decodes = decode_predictions(preds, top=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('n02895154', 'breastplate', np.float32(0.6338938))],\n",
       " [('n02132136', 'brown_bear', np.float32(0.9994437))],\n",
       " [('n02124075', 'Egyptian_cat', np.float32(0.64985096))],\n",
       " [('n02124075', 'Egyptian_cat', np.float32(0.82098436))],\n",
       " [('n02106550', 'Rottweiler', np.float32(0.7329103))],\n",
       " [('n02106030', 'collie', np.float32(0.99525696))],\n",
       " [('n02113799', 'standard_poodle', np.float32(0.32455605))],\n",
       " [('n09835506', 'ballplayer', np.float32(0.5402341))],\n",
       " [('n07873807', 'pizza', np.float32(0.99713045))]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Predicted:\n",
      " breastplate 0.6338938\n",
      "####################\n",
      "Predicted:\n",
      " brown_bear 0.9994437\n",
      "####################\n",
      "Predicted:\n",
      " Egyptian_cat 0.64985096\n",
      "####################\n",
      "Predicted:\n",
      " Egyptian_cat 0.82098436\n",
      "####################\n",
      "Predicted:\n",
      " Rottweiler 0.7329103\n",
      "####################\n",
      "Predicted:\n",
      " collie 0.99525696\n",
      "####################\n",
      "Predicted:\n",
      " standard_poodle 0.32455605\n",
      "####################\n",
      "Predicted:\n",
      " ballplayer 0.5402341\n",
      "####################\n",
      "Predicted:\n",
      " pizza 0.99713045\n"
     ]
    }
   ],
   "source": [
    "# CODE decode preds\n",
    "for j in decodes:\n",
    "    print('####################')\n",
    "    for i,decode in enumerate(j):\n",
    "        print(\"Predicted:\\n\", decode[1], decode[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16\n",
    "En este caso vamos a importar la red VGG16, que utilizaremos como red preentrenada y completaremos con una fully connected layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "IM_SIZE=32\n",
    "\n",
    "TRAIN_PATH = 'C:\\\\Users\\\\Miguel Angel\\\\Documents\\\\Bootcamp_DS_1_22\\\\datasets\\\\dogsandcats\\\\train'\n",
    "filenames = os.listdir(TRAIN_PATH)\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    categories.append(category)\n",
    "    \n",
    "df = pd.DataFrame({\n",
    "    'filenames': filenames,\n",
    "    'category': categories\n",
    "})\n",
    "\n",
    "train_df, validate_df = train_test_split(df,\n",
    "                                            test_size=0.20,\n",
    "                                            random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat.3337.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog.12039.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat.2542.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog.10283.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dog.10384.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       filenames category\n",
       "0   cat.3337.jpg      cat\n",
       "1  dog.12039.jpg      dog\n",
       "2   cat.2542.jpg      cat\n",
       "3  dog.10283.jpg      dog\n",
       "4  dog.10384.jpg      dog"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator data augmentation\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                    rotation_range = 40,\n",
    "                                    width_shift_range = 0.2,\n",
    "                                    height_shift_range = 0.2,\n",
    "                                    shear_range = 0.2,\n",
    "                                    zoom_range = 0.2,\n",
    "                                    horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5260 validated image filenames belonging to 2 classes.\n",
      "Found 1316 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                    TRAIN_PATH,\n",
    "                                                    x_col='filenames',\n",
    "                                                    y_col='category',\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (IM_SIZE, IM_SIZE))\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_dataframe(validate_df,\n",
    "                                                                TRAIN_PATH,\n",
    "                                                                x_col='filenames',\n",
    "                                                                y_col='category',\n",
    "                                                                batch_size = 20,\n",
    "                                                                class_mode = 'binary',\n",
    "                                                                target_size = (IM_SIZE, IM_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "# CODE model\n",
    "base_model = VGG16(input_shape=(IM_SIZE,IM_SIZE,3),\n",
    "                    include_top=False,\n",
    "                    weights = 'imagenet'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### FULLY CONNECTED LAYER #####\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "    \n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,977,857\n",
      "Trainable params: 14,977,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "263/263 [==============================] - 68s 257ms/step - loss: 0.6222 - acc: 0.6616 - val_loss: 0.5752 - val_acc: 0.7059\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 37s 140ms/step - loss: 0.5972 - acc: 0.6781 - val_loss: 0.5806 - val_acc: 0.7029\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 36s 136ms/step - loss: 0.5945 - acc: 0.6766 - val_loss: 0.5577 - val_acc: 0.7181\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 35s 134ms/step - loss: 0.5811 - acc: 0.6913 - val_loss: 0.5556 - val_acc: 0.7166\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 32s 123ms/step - loss: 0.5776 - acc: 0.6954 - val_loss: 0.5553 - val_acc: 0.7105\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 31s 118ms/step - loss: 0.5723 - acc: 0.6989 - val_loss: 0.5417 - val_acc: 0.7249\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 32s 121ms/step - loss: 0.5691 - acc: 0.7067 - val_loss: 0.5354 - val_acc: 0.7333\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 32s 123ms/step - loss: 0.5633 - acc: 0.7078 - val_loss: 0.5579 - val_acc: 0.7021\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 33s 125ms/step - loss: 0.5661 - acc: 0.7002 - val_loss: 0.5660 - val_acc: 0.7082\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 34s 131ms/step - loss: 0.5647 - acc: 0.6977 - val_loss: 0.5568 - val_acc: 0.7143\n"
     ]
    }
   ],
   "source": [
    "vgghist = model.fit(train_generator,\n",
    "                    validation_data = validation_generator,\n",
    "                    batch_size = 128,\n",
    "                    epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5260 validated image filenames belonging to 2 classes.\n",
      "Found 1316 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "IM_SIZE = 75\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                    TRAIN_PATH,\n",
    "                                                    x_col='filenames',\n",
    "                                                    y_col='category',\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (IM_SIZE, IM_SIZE))\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_dataframe(validate_df,\n",
    "                                                                TRAIN_PATH,\n",
    "                                                                x_col='filenames',\n",
    "                                                                y_col='category',\n",
    "                                                                batch_size = 20,\n",
    "                                                                class_mode = 'binary',\n",
    "                                                                target_size = (IM_SIZE, IM_SIZE))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "                loss = 'binary_crossentropy',\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 23s 186ms/step - loss: 0.9782 - accuracy: 0.6540 - val_loss: 0.5831 - val_accuracy: 0.7272\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 20s 205ms/step - loss: 0.6786 - accuracy: 0.6850 - val_loss: 0.6164 - val_accuracy: 0.7363\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 18s 177ms/step - loss: 0.6064 - accuracy: 0.6950 - val_loss: 0.5667 - val_accuracy: 0.7606\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 19s 189ms/step - loss: 0.6065 - accuracy: 0.7125 - val_loss: 0.6184 - val_accuracy: 0.6991\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 0.5676 - accuracy: 0.7385 - val_loss: 0.5456 - val_accuracy: 0.7470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a59ff36348>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,\n",
    "         validation_data = validation_generator,\n",
    "         steps_per_epoch = 100,\n",
    "         epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50V2 sin entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5260 validated image filenames belonging to 2 classes.\n",
      "Found 1316 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "IM_SIZE=32\n",
    "\n",
    "base_model = ResNet50V2(input_shape = (224, 224, 3),\n",
    "                       include_top = False,\n",
    "                       weights = None,\n",
    "                       classifier_activation= \"softmax\")\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                    TRAIN_PATH,\n",
    "                                                    x_col='filenames',\n",
    "                                                    y_col='category',\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (IM_SIZE, IM_SIZE))\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_dataframe(validate_df,\n",
    "                                                              TRAIN_PATH,\n",
    "                                                              x_col='filenames',\n",
    "                                                              y_col='category',\n",
    "                                                              batch_size = 20,\n",
    "                                                              class_mode = 'binary',\n",
    "                                                              target_size = (IM_SIZE, IM_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "    \n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 102s 975ms/step - loss: 3.5332 - acc: 0.8600 - val_loss: 0.4825 - val_acc: 0.9430\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.5437 - acc: 0.8930 - val_loss: 0.0976 - val_acc: 0.9605\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_generator,\n",
    "         validation_data = validation_generator,\n",
    "         steps_per_epoch = 100,\n",
    "         epochs = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
