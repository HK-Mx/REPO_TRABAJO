{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ce4f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install llama-index llama-index-utils-workflow llama-index-llms-google-genai llama-index-tools-google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93fff7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ff8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "llm = GoogleGenAI(model=\"gemini-2.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7410244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "google_search_tool = types.Tool(\n",
    "    google_search=types.GoogleSearch()\n",
    ")\n",
    "\n",
    "llm_with_search = GoogleGenAI(\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    generation_config=types.GenerateContentConfig(tools=[google_search_tool])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba3fcbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Sunny Skies and Warm Temperatures in Valencia Today\n",
      "\n",
      "**Valencia, Spain is currently experiencing a sunny day with warm temperatures.** As of 12:34 PM local time, the temperature is approximately 29¬∞C (84¬∞F). The forecast for the rest of the day indicates continued sunshine with a maximum temperature around 31¬∞C (89¬∞F) and a minimum nighttime temperature of about 24¬∞C (76¬∞F).\n",
      "\n",
      "There is a very low chance of rain throughout the day. Humidity levels are currently around 58%, and are expected to be around 69% during the day.\n",
      "\n",
      "Looking ahead, the weather in Valencia is expected to remain sunny and warm for the next several days, with temperatures gradually increasing.\n"
     ]
    }
   ],
   "source": [
    "response = llm_with_search.complete(\"What's the weather like today in Valencia, Spain?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6ceaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Context\n",
    "\n",
    "async def planning(ctx: Context, query: str) -> str:\n",
    "    \n",
    "    prompt = f\"\"\"Search in Internet and Create a detailed plan for execute a complete investigation about the specify topic from the query: \"{query},\"\n",
    "    Please provide the research plan.\"\"\"\n",
    "\n",
    "    response = await llm_with_search.acomplete(prompt)\n",
    "    \n",
    "    current_state = await ctx.store.get(\"state\")\n",
    "    \n",
    "    current_state[\"research_plan\"] = {}\n",
    "    current_state[\"research_plan\"][query] = response.text\n",
    "    await ctx.store.set(\"state\", current_state)\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "async def search_web(ctx: Context, query: str) -> str:\n",
    "    \"\"\"Useful for searching the web about a specific query or topic\"\"\"\n",
    "    response = await llm_with_search.acomplete(f\"\"\"Please research given this query or topic,\n",
    "    and return the result\\n<query_or_topic>{query}</query_or_topic>\"\"\")\n",
    "    return response\n",
    "\n",
    "async def record_notes(ctx: Context, notes: str, notes_title: str) -> str:\n",
    "    \"\"\"Useful for recording notes on a given topic.\"\"\"\n",
    "    current_state = await ctx.store.get(\"state\")\n",
    "    if \"research_notes\" not in current_state:\n",
    "        current_state[\"research_notes\"] = {}\n",
    "    current_state[\"research_notes\"][notes_title] = notes\n",
    "    await ctx.store.set(\"state\", current_state)\n",
    "    return \"Notes recorded.\"\n",
    "\n",
    "async def write_report(ctx: Context, report_content: str) -> str:\n",
    "    \"\"\"Useful for writing a report on a given topic.\"\"\"\n",
    "    current_state = await ctx.store.get(\"state\")\n",
    "    current_state[\"report_content\"] = report_content\n",
    "    await ctx.store.set(\"state\", current_state)\n",
    "    return \"Report written.\"\n",
    "\n",
    "async def review_report(ctx: Context, review: str) -> str:\n",
    "    \"\"\"Useful for reviewing a report and providing feedback.\"\"\"\n",
    "    current_state = await ctx.store.get(\"state\")\n",
    "    current_state[\"review\"] = review\n",
    "    await ctx.store.set(\"state\", current_state)\n",
    "    return \"Report reviewed.\"\n",
    "\n",
    "async def save_report(ctx: Context, review):\n",
    "    current_state = await ctx.store.get(\"state\")\n",
    "    \n",
    "    with open(\"report.md\", \"w\", encoding=\"utf-8\") as archivo:\n",
    "            archivo.write(current_state[\"report_content\"])\n",
    "    \n",
    "    return f\"Contenido guardado exitosamente en report.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86e5dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import (\n",
    "    AgentInput,\n",
    "    AgentOutput,\n",
    "    ToolCall,\n",
    "    ToolCallResult,\n",
    "    AgentStream,\n",
    ")\n",
    "from llama_index.core.agent.workflow import FunctionAgent, ReActAgent\n",
    "\n",
    "planning_agent = FunctionAgent(\n",
    "    name=\"PlanningAgent\",\n",
    "    description=\"Useful for planning\",\n",
    "    system_prompt=(\n",
    "        \"You are the PlanningAgent that can make the plan for information on a given topic and send this plan to the research_agent. \"\n",
    "        \"Once the planning are complete and you are satisfied, you should hand off control to the ResearchAgent to start searching info following your plan about the topic.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[planning, record_notes],\n",
    "    can_handoff_to=[\"ResearchAgent\"],\n",
    ")\n",
    "\n",
    "research_agent = FunctionAgent(\n",
    "    name=\"ResearchAgent\",\n",
    "    description=\"Useful for searching the web for information on a given topic and recording notes on the topic.\",\n",
    "    system_prompt=(\n",
    "        \"You are the ResearchAgent that can search the web for information on a given topic and record notes on the topic. \"\n",
    "        \"Once notes are recorded and you are satisfied, you should hand off control to the WriteAgent to write a report on the topic.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[search_web, record_notes],\n",
    "    can_handoff_to=[\"WriteAgent\"],\n",
    ")\n",
    "\n",
    "write_agent = FunctionAgent(\n",
    "    name=\"WriteAgent\",\n",
    "    description=\"Useful for writing a report on a given topic.\",\n",
    "    system_prompt=(\n",
    "        \"You are the WriteAgent that can write a report on a given topic. \"\n",
    "        \"Your report should be in a markdown format. The content should be grounded in the research notes. \"\n",
    "        \"Once the report is written, you should get feedback at least once from the ReviewAgent.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[write_report],\n",
    "    can_handoff_to=[\"ReviewAgent\", \"ResearchAgent\"],\n",
    ")\n",
    "\n",
    "review_agent = FunctionAgent(\n",
    "    name=\"ReviewAgent\",\n",
    "    description=\"Useful for reviewing a report and providing feedback.\",\n",
    "    system_prompt=(\n",
    "        \"You are the ReviewAgent that can review a report and provide feedback. \"\n",
    "        \"Your feedback should either approve the current report or request changes for the WriteAgent to implement.\"\n",
    "        \"Once the review is done, you should save the report.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[review_report,save_report],\n",
    "    can_handoff_to=[\"ResearchAgent\",\"WriteAgent\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ae55e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import AgentWorkflow\n",
    "\n",
    "agent_workflow = AgentWorkflow(\n",
    "    agents=[planning_agent, research_agent, write_agent, review_agent],\n",
    "    root_agent=research_agent.name,\n",
    "    initial_state={\n",
    "        \"plan: Not written yet.\"\n",
    "        \"research_notes\": {},\n",
    "        \"report_content\": \"Not written yet.\",\n",
    "        \"review\": \"Review required.\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed75cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ü§ñ Agent: ResearchAgent\n",
      "==================================================\n",
      "\n",
      "üõ†Ô∏è  Planning to use tools: ['search_web']\n",
      "üî® Calling Tool: search_web\n",
      "  With arguments: {'query': 'current landscape of AI and LLMs'}\n",
      "üîß Tool Result (search_web):\n",
      "  Arguments: {'query': 'current landscape of AI and LLMs'}\n",
      "  Output: \n",
      "üõ†Ô∏è  Planning to use tools: ['search_web']\n",
      "üî® Calling Tool: search_web\n",
      "  With arguments: {'query': 'AI and LLM landscape 2024'}\n",
      "üîß Tool Result (search_web):\n",
      "  Arguments: {'query': 'AI and LLM landscape 2024'}\n",
      "  Output: ## AI and LLM Landscape in 2024: A Year of Accelerated Integration and Maturing Capabilities\n",
      "\n",
      "The year 2024 has marked a pivotal moment in the evolution of artificial intelligence (AI) and large language models (LLMs), characterized by a distinct shift from experimental enthusiasm to widespread, production-grade implementation across industries. While groundbreaking innovations continue to emerge, the overarching theme of the year has been the practical application and scaling of these technologies, alongside a growing awareness of the associated challenges, from security vulnerabilities to ethical considerations.\n",
      "\n",
      "### Key Trends Shaping the 2024 Landscape\n",
      "\n",
      "Several key trends have defined the trajectory of AI and LLMs in 2024. A major development has been the significant enhancement of **multimodal capabilities**, with models increasingly able to process and generate content across text, images, and audio in real-time. This has expanded their applicability in diverse fields, from training autonomous vehicles to creating more intuitive and human-like conversational AI.\n",
      "\n",
      "**Hyper-personalization** has also become a focal point, with LLMs now capable of tailoring interactions to individual user needs and preferences with remarkable accuracy. This is particularly evident in customer service, where AI-powered chatbots can recall past interactions to provide a seamless experience.\n",
      "\n",
      "Furthermore, 2024 has witnessed a significant move towards **deploying LLMs in diverse and scalable environments**, from large enterprises to small businesses. This has been facilitated by advancements in cloud computing and edge AI, allowing these models to operate efficiently even in resource-constrained settings. The year also saw a surge in enterprise spending on generative AI applications, indicating a clear shift from experimentation to execution.\n",
      "\n",
      "### The Titans of AI: Major Players and Their Innovations\n",
      "\n",
      "The AI and LLM landscape in 2024 remains dominated by a handful of tech giants who continue to push the boundaries of innovation.\n",
      "\n",
      "*   **OpenAI**, a leading force, continued to advance its powerful models like the GPT series, including the introduction of GPT-4o with its impressive multimodal capabilities.\n",
      "*   **Google** has been a dominant player with its Gemini models, including the advanced Gemini 2.0 and the Trillium AI chip. Waymo, Google's autonomous vehicle company, is leveraging the Gemini model to train its robotaxis.\n",
      "*   **Meta** has championed the open-source movement with its Llama series, with the upcoming Llama 4 model being trained on an extensive GPU cluster. Their LLaMa 3.1 model has shown performance on par with or even outperforming some closed models.\n",
      "*   **Anthropic**, co-founded by former OpenAI executives, has gained significant traction with its focus on AI safety and its Claude series of models.\n",
      "*   **Microsoft** has solidified its position through a strategic partnership with OpenAI, integrating its models into the Azure cloud platform and products like Copilot Pro.\n",
      "\n",
      "Other notable players include **NVIDIA**, whose GPUs are critical for training and running large-scale AI models, and startups like **Cohere** and **Character.ai** who are making strides in conversational AI.\n",
      "\n",
      "### The Great Debate: Open Source vs. Proprietary Models\n",
      "\n",
      "A central and ongoing discussion in the 2024 AI landscape is the choice between open-source and proprietary LLMs.\n",
      "\n",
      "**Proprietary models**, such as OpenAI's GPT series and Google's Gemini, are developed and controlled by single organizations. They often boast high performance, extensive resources for development, and dedicated customer support, making them a popular choice for large-scale commercial applications.\n",
      "\n",
      "On the other hand, **open-source LLMs**, like Meta's Llama, Mistral, and Falcon, offer transparency, flexibility, and cost-effectiveness. Their publicly accessible code allows for greater customization and a collaborative development environment, fostering innovation and making AI more accessible. While traditionally seen as having a performance gap, open-source models are increasingly closing in on their proprietary counterparts. The choice between the two ultimately depends on an organization's specific needs, budget, and desired level of control.\n",
      "\n",
      "### Real-World Impact: Applications Across Industries\n",
      "\n",
      "The integration of AI and LLMs has accelerated across numerous sectors in 2024, transforming workflows and creating new possibilities.\n",
      "\n",
      "*   **Customer Support:** AI-powered chatbots are providing 24/7, personalized customer service, handling inquiries and resolving issues with increasing sophistication.\n",
      "*   **Content Creation:** LLMs are augmenting human creativity by generating novel ideas, writing text, and even creating images and videos.\n",
      "*   **Healthcare:** These models are assisting in medical diagnosis, analyzing patient data, and personalizing treatment plans.\n",
      "*   **Education:** AI tutors are providing personalized learning experiences and feedback to students.\n",
      "*   **Software Development:** Generative AI is being used to automate coding tasks, making development more efficient.\n",
      "*   **Audio Data Analysis:** LLMs are being used to transcribe and analyze hours of audio recordings, turning them into actionable insights.\n",
      "\n",
      "### Navigating the Frontier: Challenges and Risks\n",
      "\n",
      "Despite the rapid advancements, the widespread adoption of AI and LLMs in 2024 has brought a number of challenges and risks to the forefront.\n",
      "\n",
      "*   **Security:** New vulnerabilities have emerged, including prompt injection attacks, data leaks, and the potential for AI systems to be used for malicious purposes like state-sponsored hacking. The security of the LLM supply chain is also a growing concern.\n",
      "*   **Ethical Considerations and Bias:** Ensuring fairness, transparency, and mitigating bias in AI models remains a critical challenge. There is a growing focus on developing explainable AI to understand the decision-making processes of these complex systems.\n",
      "*   **Inaccurate Outputs and \"Hallucinations\":** LLMs can sometimes generate incorrect or nonsensical information, which can have serious consequences depending on the application.\n",
      "*   **Regulatory Landscape:** The rapid evolution of AI has led to increased scrutiny from regulators, with new frameworks like the EU AI Act setting a precedent for responsible AI governance.\n",
      "\n",
      "In conclusion, 2024 has been a year of significant maturation for the AI and LLM landscape. The focus has decisively shifted towards real-world applications and enterprise adoption, with organizations across the board looking to leverage these powerful tools for tangible business value. However, as the technology becomes more deeply integrated into our daily lives, the critical need to address the associated security, ethical, and regulatory challenges has become more urgent than ever. The path forward will require a concerted effort from researchers, developers, policymakers, and society as a whole to ensure that the transformative potential of AI is realized responsibly and for the benefit of all.\n",
      "üõ†Ô∏è  Planning to use tools: ['search_web']\n",
      "üî® Calling Tool: search_web\n",
      "  With arguments: {'query': 'Google Gemini AI model details'}\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent.workflow import (\n",
    "    AgentInput,\n",
    "    AgentOutput,\n",
    "    ToolCall,\n",
    "    ToolCallResult,\n",
    "    AgentStream,\n",
    ")\n",
    "\n",
    "research_topic = \"\"\"Write a report on the current landscape of AI and LLMs, specifically Gemini.\"\"\"\n",
    "\n",
    "handler = agent_workflow.run(\n",
    "    user_msg=research_topic\n",
    ")\n",
    "\n",
    "current_agent = None\n",
    "current_tool_calls = \"\"\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if (\n",
    "        hasattr(event, \"current_agent_name\")\n",
    "        and event.current_agent_name != current_agent\n",
    "    ):\n",
    "        current_agent = event.current_agent_name\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ü§ñ Agent: {current_agent}\")\n",
    "        print(f\"{'='*50}\\n\")\n",
    "    elif isinstance(event, AgentOutput):\n",
    "        if event.response.content:\n",
    "            print(\"üì§ Output:\", event.response.content)\n",
    "        if event.tool_calls:\n",
    "            print(\n",
    "                \"üõ†Ô∏è  Planning to use tools:\",\n",
    "                [call.tool_name for call in event.tool_calls],\n",
    "            )\n",
    "    elif isinstance(event, ToolCallResult):\n",
    "        print(f\"üîß Tool Result ({event.tool_name}):\")\n",
    "        print(f\"  Arguments: {event.tool_kwargs}\")\n",
    "        print(f\"  Output: {event.tool_output}\")\n",
    "    elif isinstance(event, ToolCall):\n",
    "        print(f\"üî® Calling Tool: {event.tool_name}\")\n",
    "        print(f\"  With arguments: {event.tool_kwargs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81668398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Content:\n",
      " # The Shifting Sands of Intelligence: A Look at the Current AI and LLM Landscape, Featuring Google's Gemini\n",
      "\n",
      "## Introduction\n",
      "\n",
      "The world of Artificial Intelligence (AI) and Large Language Models (LLMs) is in a constant state of flux, characterized by rapid technological breakthroughs, substantial financial investment, and an evolving regulatory environment. The race for more powerful, efficient, and versatile models is dominated by a handful of tech giants, each pushing the boundaries of what was once thought possible. This report delves into the current landscape, with a special focus on Google's powerful Gemini model.\n",
      "\n",
      "## The Key Players\n",
      "\n",
      "The field is currently led by a few major players:\n",
      "\n",
      "*   **OpenAI:** Continues to be a dominant force with its influential GPT series.\n",
      "*   **Google:** Has made significant strides with its natively multimodal Gemini family and its open-source Gemma models.\n",
      "*   **Meta:** Contributes significantly to the open-source community with its powerful Llama series.\n",
      "*   **Anthropic:** Focuses on AI safety with its Claude family of models.\n",
      "\n",
      "## A Closer Look: Google's Gemini\n",
      "\n",
      "Google's Gemini stands out as a powerful, multimodal AI model capable of understanding and processing a wide range of information, including text, code, audio, images, and video. It is not a single model but a family of models designed for different needs:\n",
      "\n",
      "*   **Gemini Ultra:** The largest and most capable model for highly complex tasks.\n",
      "*   **Gemini Pro:** A versatile, all-around model for a wide range of applications.\n",
      "*   **Gemini Nano:** The most efficient model, designed to run directly on mobile devices.\n",
      "\n",
      "The latest iteration, **Gemini 2.0**, ushers in what Google calls the \"agentic era.\" A key model in this release is **Gemini 2.0 Flash**, which offers enhanced performance and speed. Gemini has demonstrated state-of-the-art performance across numerous academic benchmarks and is accessible to the public through the Gemini app and to developers via the Gemini API in Google AI Studio and Google Cloud Vertex AI. Looking ahead, Google's **Project Astra** aims to build upon the Gemini foundation to create a universal AI agent.\n",
      "\n",
      "## Key Trends and Innovations\n",
      "\n",
      "Across the industry, several key trends are shaping the development of LLMs:\n",
      "\n",
      "*   **Enhanced Reasoning:** A major focus is on improving the logical reasoning capabilities of models.\n",
      "*   **Multimodality:** The ability to process and integrate multiple data types (text, image, audio) is becoming standard.\n",
      "*   **Efficiency:** There is a growing emphasis on creating smaller, more cost-effective, and specialized models.\n",
      "\n",
      "## Market Growth and Regulatory Scrutiny\n",
      "\n",
      "The market for AI and LLMs is experiencing explosive growth, with widespread adoption across industries like retail, healthcare, and manufacturing. This rapid expansion has not gone unnoticed by regulators. The **European Union** has taken a significant step with the **EU AI Act**, a comprehensive piece of legislation that takes a risk-based approach to AI. In contrast, the **United States** has a more fragmented regulatory landscape, with various state-level laws addressing specific concerns like algorithmic bias and deepfakes.\n",
      "\n",
      "## Challenges and the Road Ahead\n",
      "\n",
      "Despite the incredible progress, significant challenges remain. LLMs still lack true, grounded reasoning and can be prone to generating biased or inaccurate information. The immense computational power required to train these models also raises environmental concerns.\n",
      "\n",
      "The future of AI is likely to be even more dynamic. The development of **\"Agentic AI\"**‚Äîsystems that can autonomously tackle complex tasks‚Äîis a major area of research. We can also expect to see a proliferation of smaller, more efficient, and highly specialized models tailored for specific industry needs.\n",
      "\n",
      "------------\n",
      "Final Review:\n",
      " The report is well-written, comprehensive, and accurately reflects the research notes. It successfully addresses all aspects of the initial prompt. I approve this report.\n"
     ]
    }
   ],
   "source": [
    "state = await handler.ctx.store.get(\"state\")\n",
    "print(\"Report Content:\\n\", state[\"report_content\"])\n",
    "print(\"\\n------------\\nFinal Review:\\n\", state[\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdafcd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8695e684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
